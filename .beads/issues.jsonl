{"id":"sensei-07q","title":"Implement llms.txt parser","description":"Create parse_llms_txt() function in sensei/tome/parser.py. Extract URLs from llms.txt markdown format (links in H2 sections). Return list of URLs.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-27T11:16:03.962606-05:00","updated_at":"2025-11-27T11:26:20.975411-05:00","closed_at":"2025-11-27T11:26:20.975411-05:00","dependencies":[{"issue_id":"sensei-07q","depends_on_id":"sensei-nym","type":"parent-child","created_at":"2025-11-27T11:16:03.964273-05:00","created_by":"daemon"},{"issue_id":"sensei-07q","depends_on_id":"sensei-au8","type":"blocks","created_at":"2025-11-27T11:16:18.327806-05:00","created_by":"daemon"}]}
{"id":"sensei-0ih","title":"Tome: Create SaveResult enum for storage return type","description":"Replace bool return from save_tome_document() with SaveResult enum (INSERTED, UPDATED, SKIPPED). This upstream fix enables proper tracking of documents_updated in IngestResult.","design":"```python\nclass SaveResult(Enum):\n    INSERTED = \"inserted\"\n    UPDATED = \"updated\"\n    SKIPPED = \"skipped\"  # content unchanged\n```\n\nCrawler can then:\n```python\nmatch await save_tome_document(...):\n    case SaveResult.INSERTED: result.documents_added += 1\n    case SaveResult.UPDATED: result.documents_updated += 1\n    case SaveResult.SKIPPED: result.documents_skipped += 1\n```","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-11-27T13:28:47.061712-05:00","updated_at":"2025-11-27T13:42:03.542461-05:00","closed_at":"2025-11-27T13:42:03.542461-05:00","labels":["architecture","important","tome"]}
{"id":"sensei-0nt","title":"Make database init conditional (SQLite FTS5 vs Postgres ILIKE)","description":"Detect database type from URL. Skip FTS5 virtual tables on Postgres, use ILIKE for search instead.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-27T09:00:39.676313-05:00","updated_at":"2025-11-27T09:16:22.149689-05:00","closed_at":"2025-11-27T09:16:22.149689-05:00","dependencies":[{"issue_id":"sensei-0nt","depends_on_id":"sensei-4ok","type":"parent-child","created_at":"2025-11-27T09:00:39.6772-05:00","created_by":"daemon"}]}
{"id":"sensei-0uo","title":"Add kura script entry point to pyproject.toml","description":"Add kura = \"sensei.kura:main\" to [project.scripts] so users can run `uvx --from sensei kura` for stdio MCP.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-27T08:55:29.142133-05:00","updated_at":"2025-11-27T08:58:06.351994-05:00","closed_at":"2025-11-27T08:58:06.351994-05:00","dependencies":[{"issue_id":"sensei-0uo","depends_on_id":"sensei-fnh","type":"blocks","created_at":"2025-11-27T08:55:36.527213-05:00","created_by":"daemon"}]}
{"id":"sensei-0y5","title":"Create fly.toml configuration","description":"Create fly.toml with: app name, region (iad for US East near Neon), internal port 8080, volume mount at /data, health check endpoint, memory/CPU settings.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-27T16:00:09.791005-05:00","updated_at":"2025-11-30T05:57:26.643762-05:00","closed_at":"2025-11-30T05:57:26.643762-05:00","labels":["deployment","fly.io"],"dependencies":[{"issue_id":"sensei-0y5","depends_on_id":"sensei-t0t","type":"parent-child","created_at":"2025-11-27T16:00:17.929291-05:00","created_by":"daemon"}]}
{"id":"sensei-198","title":"Add asyncpg dependency to pyproject.toml","description":"Add asyncpg for async PostgreSQL driver. Also add alembic as dependency.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-27T13:38:55.48923-05:00","updated_at":"2025-11-27T16:01:50.231857-05:00","closed_at":"2025-11-27T16:01:50.231857-05:00","labels":["database","dependencies"],"dependencies":[{"issue_id":"sensei-198","depends_on_id":"sensei-izi","type":"parent-child","created_at":"2025-11-27T13:39:08.065958-05:00","created_by":"daemon"}]}
{"id":"sensei-1c5","title":"Remove init_db() and SQLite-specific code from storage.py","description":"Remove: init_db(), is_postgres(), FTS5 virtual table, SQLite triggers, SQLite search logic in search_queries(). Keep engine/session factory and all query functions.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-27T13:38:55.42918-05:00","updated_at":"2025-11-27T16:01:50.456783-05:00","closed_at":"2025-11-27T16:01:50.456783-05:00","labels":["cleanup","database"],"dependencies":[{"issue_id":"sensei-1c5","depends_on_id":"sensei-izi","type":"parent-child","created_at":"2025-11-27T13:39:07.982994-05:00","created_by":"daemon"}]}
{"id":"sensei-1ha","title":"Create alembic.ini and alembic/env.py with async support","description":"Initialize Alembic with async engine config. Read DATABASE_URL from env. Import Base.metadata from sensei.database.models. Enable compare_type and compare_server_default.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-27T13:38:55.259893-05:00","updated_at":"2025-11-27T16:01:50.34949-05:00","closed_at":"2025-11-27T16:01:50.34949-05:00","labels":["database","migrations"],"dependencies":[{"issue_id":"sensei-1ha","depends_on_id":"sensei-izi","type":"parent-child","created_at":"2025-11-27T13:39:07.851521-05:00","created_by":"daemon"}]}
{"id":"sensei-1j9","title":"Create docker-compose.yml for local PostgreSQL","description":"PostgreSQL 16 container with volume persistence. Port 5432, credentials sensei/sensei/sensei.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-27T13:38:55.375073-05:00","updated_at":"2025-11-27T16:01:50.298951-05:00","closed_at":"2025-11-27T16:01:50.298951-05:00","labels":["database","docker"],"dependencies":[{"issue_id":"sensei-1j9","depends_on_id":"sensei-izi","type":"parent-child","created_at":"2025-11-27T13:39:07.937163-05:00","created_by":"daemon"}]}
{"id":"sensei-1qn","title":"Tome: Add rate limiting to crawler","description":"HttpCrawler configured with max_requests but no rate limiting. Could overwhelm target servers. Add max_requests_per_minute or min_request_delay.","status":"closed","priority":3,"issue_type":"feature","created_at":"2025-11-27T11:44:48.829289-05:00","updated_at":"2025-11-27T16:08:51.073521-05:00","closed_at":"2025-11-27T16:08:51.073521-05:00","labels":["minor","tome"]}
{"id":"sensei-225","title":"Tome: Validate domain parameter in ingest_domain()","description":"crawler.py:49 has no validation that domain parameter is actually a domain (not a full URL). User might pass https://react.dev instead of react.dev.","notes":"System thinking review: This is a symptom of missing Domain value object. Once sensei-kt2 is implemented, validation happens automatically when constructing Domain(user_input).","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-11-27T11:44:32.747283-05:00","updated_at":"2025-11-27T13:42:03.743659-05:00","closed_at":"2025-11-27T13:42:03.743659-05:00","labels":["important","tome"],"dependencies":[{"issue_id":"sensei-225","depends_on_id":"sensei-kt2","type":"blocks","created_at":"2025-11-27T13:28:54.941895-05:00","created_by":"daemon"}]}
{"id":"sensei-28m","title":"Deps.http_client typed as Any instead of httpx.AsyncClient","description":"deps.py:16 types http_client as Optional[Any] instead of proper type.\n\nProblems:\n1. Loses type safety\n2. tools/common.py:44-49 get_client() uses getattr patterns to work around it\n3. Caller must track whether client was created to close it\n\nFix:\n1. Type properly: `http_client: httpx.AsyncClient | None = None`\n2. Consider using httpx context manager pattern\n3. Or inject client at request start in middleware","status":"open","priority":3,"issue_type":"task","created_at":"2025-11-30T06:03:17.599112-05:00","updated_at":"2025-11-30T06:03:17.599112-05:00","labels":["cleanup","types"]}
{"id":"sensei-2r4","title":"Fix module-level database initialization in storage.py","description":"storage.py:24-28 creates engine at module import time, causing test failures when DATABASE_URL is empty. Use lazy initialization or context-based engine creation.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-11-27T11:44:29.394024-05:00","updated_at":"2025-11-27T16:01:55.594075-05:00","closed_at":"2025-11-27T16:01:55.594075-05:00","labels":["database","important"]}
{"id":"sensei-2ym","title":"Timezone coercion logic duplicated across modules","description":"Multiple places handle timezone coercion differently:\n- kura/tools.py:19-30 (_compute_age_days)\n- storage.py:173-179 (search_queries)\n\nBoth do:\n```python\nif created_at.tzinfo is None:\n    created_at = created_at.replace(tzinfo=UTC)\n```\n\nFix options:\n1. Centralize in _compute_age_days() and use everywhere\n2. Ensure DB always returns timezone-aware datetimes (server_default with timezone)\n3. Add utility function in types.py for timezone normalization","status":"open","priority":3,"issue_type":"task","created_at":"2025-11-30T06:03:17.5016-05:00","updated_at":"2025-11-30T06:03:17.5016-05:00","labels":["cleanup","database"]}
{"id":"sensei-3c9","title":"Add TomeDocument model to database","description":"Add SQLAlchemy model for TomeDocument with fields: id, domain, url, path, content, content_hash, depth, fetched_at. Add to sensei/database/models.py","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-27T11:16:02.272288-05:00","updated_at":"2025-11-27T11:26:10.678093-05:00","closed_at":"2025-11-27T11:26:10.678093-05:00","dependencies":[{"issue_id":"sensei-3c9","depends_on_id":"sensei-nym","type":"parent-child","created_at":"2025-11-27T11:16:02.275146-05:00","created_by":"daemon"}]}
{"id":"sensei-3f9","title":"Add stateless_http=True to MCP server mounts","description":"Enable stateless mode for all three MCP servers (mcp, scout, kura) in __main__.py for horizontal scaling.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-27T09:00:39.731053-05:00","updated_at":"2025-11-27T09:16:32.361168-05:00","closed_at":"2025-11-27T09:16:32.361168-05:00","dependencies":[{"issue_id":"sensei-3f9","depends_on_id":"sensei-4ok","type":"parent-child","created_at":"2025-11-27T09:00:39.731773-05:00","created_by":"daemon"}]}
{"id":"sensei-3na","title":"Add scout script entry point to pyproject.toml","description":"Add [project.scripts] with scout = \"sensei.scout:main\" and create main() function","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-27T06:14:56.291703-05:00","updated_at":"2025-11-27T06:18:27.225929-05:00","closed_at":"2025-11-27T06:18:27.225929-05:00","dependencies":[{"issue_id":"sensei-3na","depends_on_id":"sensei-mci","type":"parent-child","created_at":"2025-11-27T06:14:56.292305-05:00","created_by":"daemon"}]}
{"id":"sensei-3oe","title":"Fix test fixture asyncio.run() conflict with Alembic migrations","description":"The test_db fixture called run_migrations() which used command.upgrade() synchronously. Since the fixture is async and pytest-asyncio runs it in an event loop, calling asyncio.run() inside Alembic failed with \"cannot be called from a running event loop\". Fixed by running migrations in a ThreadPoolExecutor via run_in_executor().","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-11-27T16:12:07.24009-05:00","updated_at":"2025-11-27T16:12:11.275195-05:00","closed_at":"2025-11-27T16:12:11.275195-05:00","labels":["async","testing"]}
{"id":"sensei-3zm","title":"Verify dev server runs and builds successfully","description":"Test that npm run dev and npm run build work in the www package","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-27T13:22:28.339278-05:00","updated_at":"2025-11-27T16:14:31.592256-05:00","closed_at":"2025-11-27T16:14:31.592256-05:00","dependencies":[{"issue_id":"sensei-3zm","depends_on_id":"sensei-on8","type":"parent-child","created_at":"2025-11-27T13:22:28.340618-05:00","created_by":"daemon"},{"issue_id":"sensei-3zm","depends_on_id":"sensei-dbo","type":"blocks","created_at":"2025-11-27T13:22:35.607426-05:00","created_by":"daemon"}]}
{"id":"sensei-4ok","title":"Deploy Sensei to Cloud Run with Neon Postgres","description":"Deploy full Sensei HTTP server to Google Cloud Run with Neon Postgres database. Stateless MCP for horizontal scaling.","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-11-27T09:00:25.904011-05:00","updated_at":"2025-11-27T15:59:45.972035-05:00","closed_at":"2025-11-27T15:59:45.972035-05:00"}
{"id":"sensei-4wt","title":"Tome: Fix misleading link count logging","description":"crawler.py:90 logs \"Found {len(links)} links\" but links is already filtered at that point. Should extract total before filtering for accurate logging.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-11-27T11:44:44.144582-05:00","updated_at":"2025-11-27T16:08:50.891579-05:00","closed_at":"2025-11-27T16:08:50.891579-05:00","labels":["minor","tome"]}
{"id":"sensei-505","title":"Refactor import cycles and lazy imports in sensei package","description":"Multiple lazy imports inside functions (e.g., crawler.py importing save_tome_document inside ingest_domain) suggest poor layering. Cycles are a code smell indicating unclear boundaries. Need to analyze import graph, identify cycles, and restructure modules for clean dependency flow.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-27T13:44:08.3768-05:00","updated_at":"2025-11-27T13:52:52.722924-05:00","closed_at":"2025-11-27T13:52:52.722924-05:00","labels":["architecture","important","tech-debt"]}
{"id":"sensei-51u","title":"Create Fly volume and set secrets","description":"Run fly commands to: 1) fly launch (or fly apps create), 2) fly volumes create sensei_data --size 10, 3) fly secrets set for DATABASE_URL, ANTHROPIC_API_KEY, etc.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-27T16:00:09.914964-05:00","updated_at":"2025-11-30T05:57:26.737998-05:00","closed_at":"2025-11-30T05:57:26.737998-05:00","labels":["deployment","fly.io"],"dependencies":[{"issue_id":"sensei-51u","depends_on_id":"sensei-t0t","type":"parent-child","created_at":"2025-11-27T16:00:18.011101-05:00","created_by":"daemon"},{"issue_id":"sensei-51u","depends_on_id":"sensei-0y5","type":"blocks","created_at":"2025-11-27T16:00:24.494254-05:00","created_by":"daemon"},{"issue_id":"sensei-51u","depends_on_id":"sensei-iid","type":"blocks","created_at":"2025-11-27T16:00:24.53964-05:00","created_by":"daemon"},{"issue_id":"sensei-51u","depends_on_id":"sensei-n82","type":"blocks","created_at":"2025-11-27T16:00:24.57999-05:00","created_by":"daemon"}]}
{"id":"sensei-543","title":"Tome: Normalize subdomains in is_same_domain()","description":"parser.py:38-50 treats www.example.com and example.com as different domains. Should strip www. prefix for comparison to avoid filtering legitimate docs.","notes":"System thinking review: This is a symptom of missing Domain value object. Once sensei-kt2 is implemented, this becomes trivial - just use Domain() for comparison.","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-11-27T11:44:01.949301-05:00","updated_at":"2025-11-27T13:42:03.611821-05:00","closed_at":"2025-11-27T13:42:03.611821-05:00","labels":["critical","tome"],"dependencies":[{"issue_id":"sensei-543","depends_on_id":"sensei-kt2","type":"blocks","created_at":"2025-11-27T13:28:54.845224-05:00","created_by":"daemon"}]}
{"id":"sensei-56t","title":"Decide on UUID generation strategy for primary keys","description":"TomeDocument uses String primary key with UUID generated in Python (storage.py). Need to decide: (1) Generate UUID in Python at storage layer (current), (2) Use PostgreSQL gen_random_uuid() as server_default, (3) Use SQLAlchemy's uuid type with default. Also affects: should queries table use UUID instead of caller-provided query_id?","status":"open","priority":2,"issue_type":"task","created_at":"2025-11-27T16:12:15.997504-05:00","updated_at":"2025-11-27T16:12:15.997504-05:00","labels":["database","migrations"]}
{"id":"sensei-5wd","title":"Add asyncpg dependency to pyproject.toml","description":"Add asyncpg for Postgres async support. SQLAlchemy auto-selects driver based on DATABASE_URL prefix.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-27T09:00:39.619244-05:00","updated_at":"2025-11-27T09:10:01.260401-05:00","closed_at":"2025-11-27T09:10:01.260401-05:00","dependencies":[{"issue_id":"sensei-5wd","depends_on_id":"sensei-4ok","type":"parent-child","created_at":"2025-11-27T09:00:39.620306-05:00","created_by":"daemon"}]}
{"id":"sensei-6br","title":"Configure Vite and React Router for Framework Mode","description":"Create vite.config.ts and react-router.config.ts for Framework Mode setup","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-27T13:22:28.092242-05:00","updated_at":"2025-11-27T13:27:48.421694-05:00","closed_at":"2025-11-27T13:27:48.421694-05:00","dependencies":[{"issue_id":"sensei-6br","depends_on_id":"sensei-on8","type":"parent-child","created_at":"2025-11-27T13:22:28.094102-05:00","created_by":"daemon"},{"issue_id":"sensei-6br","depends_on_id":"sensei-apn","type":"blocks","created_at":"2025-11-27T13:22:35.39033-05:00","created_by":"daemon"}]}
{"id":"sensei-7ao","title":"Update tests to run migrations instead of create_all","description":"Tests run alembic upgrade head against test database. No create_all() shortcut. Ensures migrations are always tested.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-27T13:38:55.547898-05:00","updated_at":"2025-11-27T16:01:50.511515-05:00","closed_at":"2025-11-27T16:01:50.511515-05:00","labels":["database","testing"],"dependencies":[{"issue_id":"sensei-7ao","depends_on_id":"sensei-izi","type":"parent-child","created_at":"2025-11-27T13:39:08.142222-05:00","created_by":"daemon"},{"issue_id":"sensei-7ao","depends_on_id":"sensei-ke1","type":"blocks","created_at":"2025-11-27T13:39:08.322769-05:00","created_by":"daemon"}]}
{"id":"sensei-7d0","title":"Tome: Fix depth semantics documentation","description":"crawler.py:40,86 comment says \"0 = llms.txt only\" but code with max_depth=0 still crawls llms.txt. Documentation doesn't match behavior.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-11-27T11:44:36.082348-05:00","updated_at":"2025-11-27T16:08:50.831049-05:00","closed_at":"2025-11-27T16:08:50.831049-05:00","labels":["minor","tome"]}
{"id":"sensei-7f4","title":"Tome: Track documents_updated correctly in IngestResult","description":"crawler.py:71-83 only tracks documents_added and documents_skipped. documents_updated always stays at 0. Modify save_tome_document() to distinguish new/updated/skipped.","notes":"System thinking review: This is a symptom of bool return type from storage. Once sensei-0ih (SaveResult enum) is implemented, tracking becomes trivial with pattern matching.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-11-27T11:44:21.836762-05:00","updated_at":"2025-11-27T13:42:03.811644-05:00","closed_at":"2025-11-27T13:42:03.811644-05:00","labels":["important","tome"],"dependencies":[{"issue_id":"sensei-7f4","depends_on_id":"sensei-0ih","type":"blocks","created_at":"2025-11-27T13:28:54.991289-05:00","created_by":"daemon"}]}
{"id":"sensei-7go","title":"Add kura to plugin mcpServers config","description":"Update packages/marketplace/sensei/.claude-plugin/plugin.json to include kura MCP server alongside scout.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-27T08:55:29.252771-05:00","updated_at":"2025-11-27T08:58:06.459188-05:00","closed_at":"2025-11-27T08:58:06.459188-05:00","dependencies":[{"issue_id":"sensei-7go","depends_on_id":"sensei-k1i","type":"blocks","created_at":"2025-11-27T08:55:36.594533-05:00","created_by":"daemon"}]}
{"id":"sensei-7uw","title":"Update sub_agent.py to use Kura via MCP toolset","description":"Add create_kura_server() to sub-agent toolsets for consistency with main agent. Sub-agents should have same tool access patterns.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-27T09:03:43.732217-05:00","updated_at":"2025-11-27T09:06:08.523371-05:00","closed_at":"2025-11-27T09:06:08.523371-05:00","dependencies":[{"issue_id":"sensei-7uw","depends_on_id":"sensei-x4g","type":"blocks","created_at":"2025-11-27T09:03:51.34974-05:00","created_by":"daemon"}]}
{"id":"sensei-8ec","title":"Tome: Document migration strategy for TomeDocument schema","description":"models.py:64-76 uses Base.metadata.create_all() which doesn't handle schema evolution. Document that schema changes require manual migration or Alembic setup.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-27T11:44:12.648564-05:00","updated_at":"2025-11-27T13:39:08.377067-05:00","closed_at":"2025-11-27T13:39:08.377067-05:00","labels":["important","tome"]}
{"id":"sensei-8mm","title":"Remove Cloud Run artifacts","description":"Remove .gcloudignore and Procfile since we're switching to Fly.io. Keep Dockerfile but update it for Fly.io.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-27T16:00:09.62305-05:00","updated_at":"2025-11-30T05:57:26.548242-05:00","closed_at":"2025-11-30T05:57:26.548242-05:00","labels":["cleanup","deployment"],"dependencies":[{"issue_id":"sensei-8mm","depends_on_id":"sensei-t0t","type":"parent-child","created_at":"2025-11-27T16:00:17.861005-05:00","created_by":"daemon"}]}
{"id":"sensei-9pf","title":"Build Dojo: DSPy prompt optimization from feedback","description":"DSPy plugin that optimizes Sensei's prompts using collected user feedback ratings. Uses MIPROv2 optimizer with 4-5 star rated examples as training data.","design":"## Stack\n- DSPy framework\n- MIPROv2 optimizer (joint instruction + few-shot optimization)\n\n## Input\n- User feedback ratings from existing ratings table\n- Filter to 4-5 star examples\n- Need 50-100 diverse examples\n\n## Output\n- Optimized system prompts\n- Curated few-shot examples\n\n## Integration\n- Periodic retraining when new feedback accumulates\n- Save optimized prompts for production use\n\n## Status: Stub for now\nCreate folder with README describing objective. Build after Tome.","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-11-27T11:12:59.177268-05:00","updated_at":"2025-11-27T16:00:28.806615-05:00","closed_at":"2025-11-27T16:00:28.806615-05:00"}
{"id":"sensei-9v0","title":"Add crawlee dependency to pyproject.toml","description":"Add crawlee[httpx] to dependencies in pyproject.toml","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-27T11:16:06.395559-05:00","updated_at":"2025-11-27T11:26:10.763828-05:00","closed_at":"2025-11-27T11:26:10.763828-05:00","dependencies":[{"issue_id":"sensei-9v0","depends_on_id":"sensei-nym","type":"parent-child","created_at":"2025-11-27T11:16:06.39726-05:00","created_by":"daemon"}]}
{"id":"sensei-9xe","title":"Tome: Add timeout configuration to HttpCrawler","description":"crawler.py:51-53 HttpCrawler created without timeout settings. Could hang indefinitely on slow/dead servers. Add request_handler_timeout_secs.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-11-27T11:44:26.124788-05:00","updated_at":"2025-11-27T13:42:05.769835-05:00","closed_at":"2025-11-27T13:42:05.769835-05:00","labels":["important","tome"]}
{"id":"sensei-afa","title":"Prepare pyproject.toml for PyPI publishing","description":"Add required metadata: authors, license, classifiers, urls, etc.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-27T06:14:56.330399-05:00","updated_at":"2025-11-27T06:20:07.826302-05:00","closed_at":"2025-11-27T06:20:07.826302-05:00","dependencies":[{"issue_id":"sensei-afa","depends_on_id":"sensei-mci","type":"parent-child","created_at":"2025-11-27T06:14:56.331062-05:00","created_by":"daemon"}]}
{"id":"sensei-anj","title":"Create Procfile for Cloud Run","description":"Add Procfile with: web: uvicorn sensei.__main__:app --host 0.0.0.0 --port $PORT","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-27T09:00:39.789268-05:00","updated_at":"2025-11-27T09:16:41.222625-05:00","closed_at":"2025-11-27T09:16:41.222625-05:00","dependencies":[{"issue_id":"sensei-anj","depends_on_id":"sensei-4ok","type":"parent-child","created_at":"2025-11-27T09:00:39.78984-05:00","created_by":"daemon"}]}
{"id":"sensei-apn","title":"Initialize packages/www directory and package.json","description":"Create the www package directory and configure package.json with React Router v7 Framework Mode dependencies","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-27T13:22:28.022327-05:00","updated_at":"2025-11-27T13:27:48.360399-05:00","closed_at":"2025-11-27T13:27:48.360399-05:00","dependencies":[{"issue_id":"sensei-apn","depends_on_id":"sensei-on8","type":"parent-child","created_at":"2025-11-27T13:22:28.024215-05:00","created_by":"daemon"}]}
{"id":"sensei-au8","title":"Create sensei/tome/ module structure","description":"Create sensei/tome/ with __init__.py, crawler.py, parser.py. Basic module structure for Tome.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-27T11:16:03.087901-05:00","updated_at":"2025-11-27T11:26:10.723597-05:00","closed_at":"2025-11-27T11:26:10.723597-05:00","dependencies":[{"issue_id":"sensei-au8","depends_on_id":"sensei-nym","type":"parent-child","created_at":"2025-11-27T11:16:03.089268-05:00","created_by":"daemon"}]}
{"id":"sensei-bgr","title":"Decide on created_at server_default strategy","description":"Migration has created_at columns without server_default. Need to decide: (1) Use server_default=sa.func.now() so DB handles timestamps even for raw SQL inserts, (2) Keep Python-only default and ensure all inserts go through ORM, (3) Use timezone-aware now() function. Also consider: should models.py Column definitions match migration server_defaults?","status":"open","priority":2,"issue_type":"task","created_at":"2025-11-27T16:10:31.669066-05:00","updated_at":"2025-11-27T16:10:31.669066-05:00","labels":["database","migrations"]}
{"id":"sensei-bti","title":"Extract cache into kura module","description":"Create sensei/kura/ module mirroring Scout's structure. Extract existing cache functionality from sensei/tools/cache.py. Connect to same SQLite database as main Sensei app.","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-11-27T08:55:29.016538-05:00","updated_at":"2025-11-27T08:57:25.865367-05:00","closed_at":"2025-11-27T08:57:25.865367-05:00"}
{"id":"sensei-cfg","title":"Tome: Use proper public suffix resolution for domain comparison","description":"Current Domain value object only strips www. prefix, but subdomains like api.example.com, docs.example.com should resolve to the same root domain (example.com). Need proper public suffix handling (e.g., tldextract library) to correctly identify registrable domain. Example: foo.bar.co.uk should resolve to bar.co.uk, not co.uk.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-11-27T13:44:08.328063-05:00","updated_at":"2025-11-27T13:58:32.321651-05:00","closed_at":"2025-11-27T13:58:32.321651-05:00","labels":["architecture","important","tome"]}
{"id":"sensei-cn3","title":"Deploy to Cloud Run","description":"Run: gcloud run deploy sensei --source . --region us-east1. Configure secrets for API keys and DATABASE_URL.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-27T09:00:39.914569-05:00","updated_at":"2025-11-27T15:59:46.012164-05:00","closed_at":"2025-11-27T15:59:46.012164-05:00","dependencies":[{"issue_id":"sensei-cn3","depends_on_id":"sensei-4ok","type":"parent-child","created_at":"2025-11-27T09:00:39.915243-05:00","created_by":"daemon"},{"issue_id":"sensei-cn3","depends_on_id":"sensei-5wd","type":"blocks","created_at":"2025-11-27T09:00:51.527228-05:00","created_by":"daemon"},{"issue_id":"sensei-cn3","depends_on_id":"sensei-0nt","type":"blocks","created_at":"2025-11-27T09:00:51.568133-05:00","created_by":"daemon"},{"issue_id":"sensei-cn3","depends_on_id":"sensei-3f9","type":"blocks","created_at":"2025-11-27T09:00:51.6073-05:00","created_by":"daemon"},{"issue_id":"sensei-cn3","depends_on_id":"sensei-anj","type":"blocks","created_at":"2025-11-27T09:00:51.645743-05:00","created_by":"daemon"},{"issue_id":"sensei-cn3","depends_on_id":"sensei-z8x","type":"blocks","created_at":"2025-11-27T09:00:51.68622-05:00","created_by":"daemon"}]}
{"id":"sensei-cox","title":"Set up TailwindCSS v4","description":"Configure TailwindCSS v4 with Vite plugin and base styles","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-27T13:22:28.152555-05:00","updated_at":"2025-11-27T13:27:48.472576-05:00","closed_at":"2025-11-27T13:27:48.472576-05:00","dependencies":[{"issue_id":"sensei-cox","depends_on_id":"sensei-on8","type":"parent-child","created_at":"2025-11-27T13:22:28.153763-05:00","created_by":"daemon"},{"issue_id":"sensei-cox","depends_on_id":"sensei-6br","type":"blocks","created_at":"2025-11-27T13:22:35.425621-05:00","created_by":"daemon"}]}
{"id":"sensei-dbo","title":"Create root.tsx entry point and routes","description":"Create src/root.tsx (HTML shell), src/routes.ts, and src/routes/home.tsx placeholder","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-27T13:22:28.277674-05:00","updated_at":"2025-11-27T13:27:48.582151-05:00","closed_at":"2025-11-27T13:27:48.582151-05:00","dependencies":[{"issue_id":"sensei-dbo","depends_on_id":"sensei-on8","type":"parent-child","created_at":"2025-11-27T13:22:28.278804-05:00","created_by":"daemon"},{"issue_id":"sensei-dbo","depends_on_id":"sensei-6br","type":"blocks","created_at":"2025-11-27T13:22:35.508318-05:00","created_by":"daemon"},{"issue_id":"sensei-dbo","depends_on_id":"sensei-cox","type":"blocks","created_at":"2025-11-27T13:22:35.554226-05:00","created_by":"daemon"}]}
{"id":"sensei-ddo","title":"Tome: Handle port numbers in domain comparison","description":"parser.py:48-50 netloc comparison includes port numbers - example.com:443 != example.com. Should strip default ports (80/443) during comparison.","notes":"System thinking review: This is a symptom of missing Domain value object. Once sensei-kt2 is implemented, port stripping happens automatically in Domain._normalize().","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-11-27T11:44:07.128291-05:00","updated_at":"2025-11-27T13:42:03.676023-05:00","closed_at":"2025-11-27T13:42:03.676023-05:00","labels":["critical","tome"],"dependencies":[{"issue_id":"sensei-ddo","depends_on_id":"sensei-kt2","type":"blocks","created_at":"2025-11-27T13:28:54.887605-05:00","created_by":"daemon"}]}
{"id":"sensei-die","title":"Build and publish sensei to PyPI","description":"Use uv build and uv publish to publish package","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-27T06:14:56.447842-05:00","updated_at":"2025-11-27T06:15:23.12644-05:00","closed_at":"2025-11-27T06:15:23.12644-05:00","dependencies":[{"issue_id":"sensei-die","depends_on_id":"sensei-mci","type":"parent-child","created_at":"2025-11-27T06:14:56.448451-05:00","created_by":"daemon"}]}
{"id":"sensei-eg1","title":"RatingRequest duplicates Rating model - violates single source of truth","description":"server/models.py:47 defines RatingRequest with the same 7 fields as types.py:132 Rating model. This violates \"define domain models once in types.py\" principle.\n\nFiles affected:\n- sensei/server/models.py (RatingRequest)\n- sensei/types.py (Rating)\n\nFix options:\n1. Use Rating directly as request model in API\n2. RatingRequest inherits from Rating, only adding json_schema_extra for examples","status":"open","priority":2,"issue_type":"task","created_at":"2025-11-30T06:03:17.207517-05:00","updated_at":"2025-11-30T06:03:17.207517-05:00","labels":["architecture","cleanup"]}
{"id":"sensei-fnh","title":"Add kura MCP server with stdio mode","description":"Create server.py with FastMCP wrapping cache functions (search_cache, get_cached_response). Add __main__.py for stdio entry point. Mirror Scout's server pattern.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-27T08:55:29.090543-05:00","updated_at":"2025-11-27T08:57:25.907756-05:00","closed_at":"2025-11-27T08:57:25.907756-05:00","dependencies":[{"issue_id":"sensei-fnh","depends_on_id":"sensei-bti","type":"blocks","created_at":"2025-11-27T08:55:36.496058-05:00","created_by":"daemon"}]}
{"id":"sensei-gdv","title":"Add ingest_domain() public API","description":"Create async def ingest_domain(domain: str, max_depth: int = 3) -\u003e IngestResult in sensei/tome/__init__.py. This is the main entry point for crawling a domain's llms.txt.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-27T11:16:05.602081-05:00","updated_at":"2025-11-27T11:27:50.74934-05:00","closed_at":"2025-11-27T11:27:50.74934-05:00","dependencies":[{"issue_id":"sensei-gdv","depends_on_id":"sensei-nym","type":"parent-child","created_at":"2025-11-27T11:16:05.603335-05:00","created_by":"daemon"},{"issue_id":"sensei-gdv","depends_on_id":"sensei-zii","type":"blocks","created_at":"2025-11-27T11:16:18.536978-05:00","created_by":"daemon"}]}
{"id":"sensei-ggd","title":"Deploy to Fly.io and verify","description":"Run fly deploy, verify app is running, test /health endpoint, test MCP endpoints, verify Scout can clone repos to /data volume.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-27T16:00:09.981935-05:00","updated_at":"2025-11-30T05:57:26.787413-05:00","closed_at":"2025-11-30T05:57:26.787413-05:00","labels":["deployment","fly.io"],"dependencies":[{"issue_id":"sensei-ggd","depends_on_id":"sensei-t0t","type":"parent-child","created_at":"2025-11-27T16:00:18.052622-05:00","created_by":"daemon"},{"issue_id":"sensei-ggd","depends_on_id":"sensei-51u","type":"blocks","created_at":"2025-11-27T16:00:24.630788-05:00","created_by":"daemon"}]}
{"id":"sensei-gun","title":"Tome: Move UUID generation to storage layer","description":"crawler.py:72 caller generates UUID instead of storage layer defaulting it. Make id parameter optional with default in save_tome_document().","status":"closed","priority":3,"issue_type":"task","created_at":"2025-11-27T11:44:47.570845-05:00","updated_at":"2025-11-27T16:08:50.950692-05:00","closed_at":"2025-11-27T16:08:50.950692-05:00","labels":["minor","tome"]}
{"id":"sensei-hkk","title":"save_query takes individual fields instead of domain model","description":"storage.py:53-64 save_query() takes 10 individual parameters while save_rating() correctly accepts the Rating domain model.\n\nThis violates: \"Pass models, not individual fields\"\n\nFix: Create QueryInput model in types.py and refactor save_query to accept it:\n```python\nasync def save_query(query: QueryInput) -\u003e None:\n    ...\n```\n\nFiles affected:\n- sensei/database/storage.py\n- sensei/types.py (add QueryInput model)\n- sensei/core.py (update call sites)","status":"open","priority":3,"issue_type":"task","created_at":"2025-11-30T06:03:17.402667-05:00","updated_at":"2025-11-30T06:03:17.402667-05:00","labels":["architecture","cleanup"]}
{"id":"sensei-hon","title":"Tome: Return Success[IngestResult] | NoResults instead of raw IngestResult","description":"ingest_domain() returns IngestResult directly. Per CLAUDE.md Result Types, tools should return Success[T] | NoResults pattern.","notes":"System thinking review: Part of error boundary pattern. Should be done together with typed exceptions (sensei-rhx) as they're both about proper edge handling.","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-11-27T11:43:46.263262-05:00","updated_at":"2025-11-27T13:42:04.653563-05:00","closed_at":"2025-11-27T13:42:04.653563-05:00","labels":["critical","tome"]}
{"id":"sensei-iid","title":"Update Dockerfile for Fly.io deployment","description":"Update existing Dockerfile: add gcc/g++ for numpy build, use PORT env var, ensure uv sync works correctly. Reference /data mount point for Scout cache.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-27T16:00:09.696172-05:00","updated_at":"2025-11-30T05:57:26.599434-05:00","closed_at":"2025-11-30T05:57:26.599434-05:00","labels":["deployment","fly.io"],"dependencies":[{"issue_id":"sensei-iid","depends_on_id":"sensei-t0t","type":"parent-child","created_at":"2025-11-27T16:00:17.892747-05:00","created_by":"daemon"},{"issue_id":"sensei-iid","depends_on_id":"sensei-8mm","type":"blocks","created_at":"2025-11-27T16:00:24.428165-05:00","created_by":"daemon"}]}
{"id":"sensei-izi","title":"Set up Alembic for PostgreSQL migrations","description":"Replace init_db() with Alembic. PostgreSQL-only (drop SQLite). CLI-driven migrations, not at app startup.","design":"## Decisions\n- Migrations run via CLI only (avoids race conditions with Cloud Run replicas)\n- DATABASE_URL from environment variable (standard Alembic pattern)\n- Fresh start (data is disposable)\n- Full downgrade support (useful for branch switching)\n- Tests run migrations (no create_all shortcut)\n- PostgreSQL only (drop SQLite support)","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-11-27T13:38:39.292935-05:00","updated_at":"2025-11-27T16:01:50.570063-05:00","closed_at":"2025-11-27T16:01:50.570063-05:00","labels":["database","migrations"]}
{"id":"sensei-ja0","title":"Tome: Clean up Crawlee storage directory after crawl","description":"Crawlee creates storage/ directory with request queues and state. No cleanup after crawl. Accumulates disk space and could interfere with subsequent crawls.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-11-27T11:44:40.144904-05:00","updated_at":"2025-11-27T16:08:51.011648-05:00","closed_at":"2025-11-27T16:08:51.011648-05:00","labels":["minor","tome"]}
{"id":"sensei-jmk","title":"Tome: Add content-type checking for responses","description":"Design doc mentions is_markdown_content() but not implemented. Could prevent crawling non-markdown responses (HTML, JSON). Consider adding content-type validation.","status":"closed","priority":3,"issue_type":"feature","created_at":"2025-11-27T11:44:46.408882-05:00","updated_at":"2025-11-27T16:10:14.644596-05:00","closed_at":"2025-11-27T16:10:14.644596-05:00","labels":["minor","tome"]}
{"id":"sensei-k1i","title":"Mount kura MCP server in main Sensei app","description":"Add HTTP endpoint for kura MCP at /kura/mcp in sensei/__main__.py, similar to how Scout is mounted at /scout/mcp.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-27T08:55:29.197141-05:00","updated_at":"2025-11-27T08:58:06.405082-05:00","closed_at":"2025-11-27T08:58:06.405082-05:00","dependencies":[{"issue_id":"sensei-k1i","depends_on_id":"sensei-fnh","type":"blocks","created_at":"2025-11-27T08:55:36.561192-05:00","created_by":"daemon"}]}
{"id":"sensei-ke1","title":"Create initial migration with all 3 tables","description":"Create 001_initial_schema.py with queries, ratings, tome_documents tables. Include all constraints, indexes, foreign keys. Full downgrade support.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-27T13:38:55.319483-05:00","updated_at":"2025-11-27T16:01:50.401331-05:00","closed_at":"2025-11-27T16:01:50.401331-05:00","labels":["database","migrations"],"dependencies":[{"issue_id":"sensei-ke1","depends_on_id":"sensei-izi","type":"parent-child","created_at":"2025-11-27T13:39:07.894251-05:00","created_by":"daemon"},{"issue_id":"sensei-ke1","depends_on_id":"sensei-1ha","type":"blocks","created_at":"2025-11-27T13:39:08.212697-05:00","created_by":"daemon"},{"issue_id":"sensei-ke1","depends_on_id":"sensei-198","type":"blocks","created_at":"2025-11-27T13:39:08.264434-05:00","created_by":"daemon"}]}
{"id":"sensei-kt2","title":"Tome: Create Domain value object with normalization","description":"Create a Domain value object that normalizes on construction: strips protocol, removes www. prefix, removes default ports (80/443), lowercases. This upstream fix simplifies issues sensei-543 (subdomain), sensei-ddo (ports), sensei-225 (validation).","design":"```python\n@dataclass(frozen=True)\nclass Domain:\n    value: str\n    \n    def __post_init__(self):\n        normalized = self._normalize(self.value)\n        object.__setattr__(self, 'value', normalized)\n    \n    @staticmethod\n    def _normalize(raw: str) -\u003e str:\n        if \"://\" in raw:\n            raw = raw.split(\"://\", 1)[1]\n        raw = raw.split(\"/\")[0]\n        raw = raw.removeprefix(\"www.\")\n        raw = re.sub(r':(?:80|443)$', '', raw)\n        return raw.lower()\n```\n\nOnce this exists:\n- is_same_domain() becomes: `Domain(url1) == Domain(url2)`\n- ingest_domain() validates by constructing Domain\n- No scattered normalization logic","status":"closed","priority":0,"issue_type":"feature","created_at":"2025-11-27T13:28:46.143648-05:00","updated_at":"2025-11-27T13:42:03.480346-05:00","closed_at":"2025-11-27T13:42:03.480346-05:00","labels":["architecture","critical","tome"]}
{"id":"sensei-l5w","title":"Global mutable state in exec_plan.py is not request-scoped","description":"tools/exec_plan.py:18 uses module-level mutable dict `_exec_plans: Dict[str, str] = {}` for storing ExecPlans.\n\nProblems:\n- Not thread-safe for concurrent requests\n- No cleanup mechanism if clear_plan() isn't called\n- State persists across requests in same process\n\nFix options:\n1. Use contextvars for request-scoped state\n2. Move to database or Redis for persistence\n3. Attach to Deps object which is per-request","status":"open","priority":2,"issue_type":"task","created_at":"2025-11-30T06:03:17.301718-05:00","updated_at":"2025-11-30T06:03:17.301718-05:00","labels":["architecture","concurrency"]}
{"id":"sensei-ljd","title":"Write CLAUDE.md snippet for plugin README","description":"Create instructions for users to copy into their CLAUDE.md. Prioritize spawning sensei agent for ANY research task. Document MCP tools (scout, kura) as secondary/direct access options.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-27T08:55:29.317689-05:00","updated_at":"2025-11-27T08:58:45.077401-05:00","closed_at":"2025-11-27T08:58:45.077401-05:00"}
{"id":"sensei-lnu","title":"Build and publish sensei to PyPI","description":"Use uv build and uv publish to publish package","notes":"Package built successfully. Waiting for PyPI account recovery to publish. Run `uv publish` when ready.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-27T06:15:01.305215-05:00","updated_at":"2025-11-27T06:33:16.918807-05:00","closed_at":"2025-11-27T06:33:16.918807-05:00","dependencies":[{"issue_id":"sensei-lnu","depends_on_id":"sensei-mci","type":"parent-child","created_at":"2025-11-27T06:15:01.305847-05:00","created_by":"daemon"},{"issue_id":"sensei-lnu","depends_on_id":"sensei-u5g","type":"blocks","created_at":"2025-11-27T06:15:07.495691-05:00","created_by":"daemon"},{"issue_id":"sensei-lnu","depends_on_id":"sensei-3na","type":"blocks","created_at":"2025-11-27T06:15:07.520515-05:00","created_by":"daemon"},{"issue_id":"sensei-lnu","depends_on_id":"sensei-afa","type":"blocks","created_at":"2025-11-27T06:15:07.548945-05:00","created_by":"daemon"}]}
{"id":"sensei-lzn","title":"Stub out sensei/dojo/ module","description":"Create sensei/dojo/ with __init__.py and README.md describing the objective: DSPy prompt optimization using MIPROv2 with user feedback ratings.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-27T11:16:07.203856-05:00","updated_at":"2025-11-27T11:28:17.946563-05:00","closed_at":"2025-11-27T11:28:17.946563-05:00","dependencies":[{"issue_id":"sensei-lzn","depends_on_id":"sensei-9pf","type":"parent-child","created_at":"2025-11-27T11:16:07.205529-05:00","created_by":"daemon"}]}
{"id":"sensei-mci","title":"Make scout installable via uvx --from sensei scout","description":"Add script entry point to pyproject.toml and publish sensei to PyPI so users can run `uvx --from sensei scout` for stdio MCP","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-11-27T06:14:48.004237-05:00","updated_at":"2025-11-27T06:33:16.956555-05:00","closed_at":"2025-11-27T06:33:16.956555-05:00"}
{"id":"sensei-n82","title":"Configure Scout to use /data volume for git cache","description":"Update Scout configuration to use /data directory for cloning and caching git repositories. This path will be mounted as a persistent Fly volume.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-27T16:00:09.854244-05:00","updated_at":"2025-11-30T05:57:26.690525-05:00","closed_at":"2025-11-30T05:57:26.690525-05:00","labels":["deployment","scout"],"dependencies":[{"issue_id":"sensei-n82","depends_on_id":"sensei-t0t","type":"parent-child","created_at":"2025-11-27T16:00:17.967425-05:00","created_by":"daemon"}]}
{"id":"sensei-neo","title":"Update agent.py to use Kura via MCP toolset","description":"Replace direct cache function imports (search_cache, get_cached_response) with create_kura_server() in toolsets. Remove cache tools from tools=[] list. This makes Kura consistent with Scout - both accessed via MCP.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-27T09:03:43.683223-05:00","updated_at":"2025-11-27T09:06:08.470345-05:00","closed_at":"2025-11-27T09:06:08.470345-05:00","dependencies":[{"issue_id":"sensei-neo","depends_on_id":"sensei-x4g","type":"blocks","created_at":"2025-11-27T09:03:51.319716-05:00","created_by":"daemon"}]}
{"id":"sensei-nym","title":"Build Tome: Documentation repository from llms.txt","description":"Canonical documentation repository built by crawling llms.txt files. Uses Crawlee HttpCrawler for orchestration (queue, dedup, retries, depth control) with plain httpx fetch. No Playwright needed since llms.txt and linked files are markdown.","design":"## Stack\n- Crawlee HttpCrawler for orchestration\n- httpx under the hood (no browser)\n- Sensei's existing database\n\n## Core function\n```python\nasync def ingest_domain(domain: str, max_depth: int = 3) -\u003e IngestResult\n```\n\n## Flow\n1. Fetch https://{domain}/llms.txt\n2. Parse markdown, extract links\n3. Enqueue same-domain links (respect depth)\n4. Store in tome_documents table\n\n## Why Crawlee HttpCrawler\n- Automatic RequestQueue with deduplication\n- Visited URL tracking\n- Retry logic with exponential backoff\n- Concurrency control\n- State persistence (resume interrupted crawls)\n- No parsing overhead (we're fetching markdown)\n\n## What we implement\n- parse_llms_txt_links() - extract URLs from llms.txt\n- is_same_domain() - domain filtering\n- is_markdown_content() - content type check\n- Storage layer integration","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-11-27T11:12:59.092712-05:00","updated_at":"2025-11-27T11:27:57.277048-05:00","closed_at":"2025-11-27T11:27:57.277048-05:00"}
{"id":"sensei-on8","title":"Create packages/www marketing site with React Router v7 Framework Mode","description":"Single-page product landing page for Sensei using React Router v7 Framework Mode, TailwindCSS, and React. Minimal/clean design, CTA links to GitHub README for setup instructions.","design":"## Technical Stack\n- React Router v7 Framework Mode (Vite-based)\n- TailwindCSS for styling\n- TypeScript\n- SSR enabled for SEO\n\n## Package Structure\npackages/www/\n├── package.json\n├── react-router.config.ts\n├── vite.config.ts\n├── tsconfig.json\n├── tailwind.config.ts\n├── src/\n│   ├── root.tsx (HTML shell)\n│   ├── routes.ts (route definitions)\n│   ├── routes/\n│   │   └── home.tsx (landing page)\n│   └── app.css (Tailwind imports)\n\n## Integration\n- Integrates with existing turbo monorepo\n- Uses npm workspaces (packages/www)\n- Follows existing biome/typescript conventions","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-11-27T13:22:14.763677-05:00","updated_at":"2025-11-27T16:14:31.647865-05:00","closed_at":"2025-11-27T16:14:31.647865-05:00"}
{"id":"sensei-qow","title":"Add Tome storage functions","description":"Add storage functions to sensei/database/storage.py: save_tome_document(), get_tome_document_by_url(), search_tome_documents(), delete_tome_documents_by_domain(). Upsert logic based on url, update if content_hash changed.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-27T11:16:02.359116-05:00","updated_at":"2025-11-27T11:26:50.761285-05:00","closed_at":"2025-11-27T11:26:50.761285-05:00","dependencies":[{"issue_id":"sensei-qow","depends_on_id":"sensei-nym","type":"parent-child","created_at":"2025-11-27T11:16:02.361933-05:00","created_by":"daemon"},{"issue_id":"sensei-qow","depends_on_id":"sensei-3c9","type":"blocks","created_at":"2025-11-27T11:16:18.290789-05:00","created_by":"daemon"}]}
{"id":"sensei-rhx","title":"Tome: Use typed exceptions instead of generic Exception","description":"crawler.py:100-101 catches generic Exception and appends string to errors list. Should use TransientError for network issues, BrokenInvariant for config issues per CLAUDE.md.","notes":"System thinking review: Part of error boundary confusion. Errors should be typed internally, only stringified at API edge. Consider grouping with Result type fix (sensei-hon).","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-11-27T11:43:44.722869-05:00","updated_at":"2025-11-27T13:42:03.880413-05:00","closed_at":"2025-11-27T13:42:03.880413-05:00","labels":["critical","tome"]}
{"id":"sensei-rpo","title":"Resolve search_queries_fts usage - remove or rename consistently","description":"Multiple files import search_queries_fts from storage.py. Instead of adding a backwards-compat alias, decide: rename all usages to search_queries, or keep search_queries_fts as the canonical name. Files affected: sensei/core.py, sensei/kura/tools.py, sensei/tools/sub_agent.py, tests/test_cache.py","status":"open","priority":1,"issue_type":"task","created_at":"2025-11-27T16:10:31.621192-05:00","updated_at":"2025-11-27T16:10:31.621192-05:00","labels":["cleanup","database"]}
{"id":"sensei-t0t","title":"Deploy Sensei to Fly.io with persistent volume","description":"Deploy Sensei HTTP server to Fly.io with Neon Postgres and persistent volume for Scout's git repo caching. Replaces Cloud Run approach due to filesystem persistence requirements.","design":"## Why Fly.io over Cloud Run?\n- Scout needs persistent filesystem for git repo caching\n- Cloud Run filesystem is ephemeral (resets on restart/scale)\n- Fly.io volumes provide real persistent disk at $0.15/GB/month\n\n## Architecture\n- Single Fly Machine with 1GB RAM\n- 10GB persistent volume mounted at /data for Scout cache\n- Neon Postgres for database (already configured)\n- Stateless MCP endpoints for horizontal scaling potential\n\n## Components\n- fly.toml configuration\n- Dockerfile (already exists, needs gcc for numpy)\n- Volume mount for /data\n- Environment secrets for API keys and DATABASE_URL","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-11-27T15:59:54.321949-05:00","updated_at":"2025-11-30T05:57:26.462284-05:00","closed_at":"2025-11-30T05:57:26.462284-05:00","labels":["deployment","fly.io"]}
{"id":"sensei-u5g","title":"Remove hardcoded API keys from config.py","description":"Replace hardcoded API keys with empty defaults before publishing to PyPI - SECURITY CRITICAL","status":"closed","priority":0,"issue_type":"task","created_at":"2025-11-27T06:15:01.270024-05:00","updated_at":"2025-11-27T06:17:25.346124-05:00","closed_at":"2025-11-27T06:17:25.346124-05:00","dependencies":[{"issue_id":"sensei-u5g","depends_on_id":"sensei-mci","type":"parent-child","created_at":"2025-11-27T06:15:01.270764-05:00","created_by":"daemon"}]}
{"id":"sensei-vxc","title":"Remove hardcoded API keys from config.py","description":"Replace hardcoded API keys with empty defaults before publishing to PyPI","status":"closed","priority":0,"issue_type":"task","created_at":"2025-11-27T06:14:56.372621-05:00","updated_at":"2025-11-27T06:15:23.094068-05:00","closed_at":"2025-11-27T06:15:23.094068-05:00"}
{"id":"sensei-x4g","title":"Create create_kura_server() for PydanticAI integration","description":"Create sensei/tools/kura.py with create_kura_server() function that returns MCPServerStreamableHTTP pointing to /kura/mcp with tool_prefix=\"kura\". Mirror the pattern from create_scout_server().","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-27T09:03:43.636612-05:00","updated_at":"2025-11-27T09:04:39.288012-05:00","closed_at":"2025-11-27T09:04:39.288012-05:00"}
{"id":"sensei-xnl","title":"Create TypeScript configuration","description":"Set up tsconfig.json for the www package","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-27T13:22:28.211914-05:00","updated_at":"2025-11-27T13:27:48.524646-05:00","closed_at":"2025-11-27T13:27:48.524646-05:00","dependencies":[{"issue_id":"sensei-xnl","depends_on_id":"sensei-on8","type":"parent-child","created_at":"2025-11-27T13:22:28.214195-05:00","created_by":"daemon"},{"issue_id":"sensei-xnl","depends_on_id":"sensei-apn","type":"blocks","created_at":"2025-11-27T13:22:35.47179-05:00","created_by":"daemon"}]}
{"id":"sensei-z8x","title":"Setup Neon Postgres database","description":"Create Neon project in us-east-1, get connection string for DATABASE_URL","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-27T09:00:39.848645-05:00","updated_at":"2025-11-27T10:20:12.28555-05:00","closed_at":"2025-11-27T10:20:12.28555-05:00","dependencies":[{"issue_id":"sensei-z8x","depends_on_id":"sensei-4ok","type":"parent-child","created_at":"2025-11-27T09:00:39.849367-05:00","created_by":"daemon"}]}
{"id":"sensei-zii","title":"Implement TomeCrawler with Crawlee HttpCrawler","description":"Create TomeCrawler in sensei/tome/crawler.py. Subclass or use Crawlee HttpCrawler. Handle: fetch llms.txt, parse links, enqueue same-domain markdown URLs, respect depth limit, store via storage layer.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-27T11:16:04.783373-05:00","updated_at":"2025-11-27T11:27:39.631156-05:00","closed_at":"2025-11-27T11:27:39.631156-05:00","dependencies":[{"issue_id":"sensei-zii","depends_on_id":"sensei-nym","type":"parent-child","created_at":"2025-11-27T11:16:04.784816-05:00","created_by":"daemon"},{"issue_id":"sensei-zii","depends_on_id":"sensei-au8","type":"blocks","created_at":"2025-11-27T11:16:18.364351-05:00","created_by":"daemon"},{"issue_id":"sensei-zii","depends_on_id":"sensei-07q","type":"blocks","created_at":"2025-11-27T11:16:18.406751-05:00","created_by":"daemon"},{"issue_id":"sensei-zii","depends_on_id":"sensei-qow","type":"blocks","created_at":"2025-11-27T11:16:18.449108-05:00","created_by":"daemon"},{"issue_id":"sensei-zii","depends_on_id":"sensei-9v0","type":"blocks","created_at":"2025-11-27T11:16:18.491868-05:00","created_by":"daemon"}]}
